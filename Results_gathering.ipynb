{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f862be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mbore\n",
    "import tqdm.notebook\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4670f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11017c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the things we need to load all optimisation runs\n",
    "problem_names = [\"DTLZ\", \"WFG\", \"RW\", \"WFG_HD\"]\n",
    "processed_results_dir = \"processed_results\"\n",
    "\n",
    "final_results_dir = \"final_results\"\n",
    "\n",
    "# note that these are the names used to run the code (not in the paper)\n",
    "models_and_optimizers = [\n",
    "    (\"XGB\", \"CMAES\"),\n",
    "    (\"FCNet\", \"Grad\"), # known as 'MLP' in the paper\n",
    "    (\"GP\", \"EI\"),\n",
    "]\n",
    "\n",
    "model_dict = {\n",
    "    \"XGB\": \"CMAES\",\n",
    "    \"FCNet\": \"Grad\",\n",
    "    \"GP\": \"EI\"\n",
    "}\n",
    "\n",
    "scalarizers = [\n",
    "    \"HypI\",\n",
    "    \"DomRank\",\n",
    "    \"HypCont\", # known as 'PHC' in the paper\n",
    "    \"ParEGO\", # known as 'AT' in the paper\n",
    "]\n",
    "\n",
    "# settings that we used for all problems\n",
    "gamma_start = 0.33\n",
    "gamma_end = None\n",
    "gamma_schedule = None\n",
    "budget = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b78b15",
   "metadata": {},
   "source": [
    "### Combine and save performance indicator and timing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fdfee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744f897b47be4749b19dbfaee1bab5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem set: DTLZ. 56 total problems\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3122bd0f5ff4d779113eb661612b102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: final_results\\DTLZ.npz\n",
      "Problem set: WFG. 63 total problems\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565965ba467348e491efedd92e3146f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: final_results\\WFG.npz\n",
      "Problem set: RW. 10 total problems\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55e5ed0c2884e48921f04576cb1bf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: final_results\\RW.npz\n",
      "Problem set: WFG. 27 total problems\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782f109235524747aea4382b76d5374b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: final_results\\WFG_HD.npz\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(final_results_dir):\n",
    "    os.mkdir(final_results_dir)\n",
    "    print(f\"Making directory {final_results_dir}\")\n",
    "\n",
    "for original_problem_name in tqdm.notebook.tqdm(problem_names):\n",
    "    savename = f\"{original_problem_name:s}.npz\"\n",
    "    savepath = os.path.join(final_results_dir, savename)\n",
    "\n",
    "    if os.path.exists(savepath):\n",
    "        print(f\"Results file already exists, skipping: {savepath:s}\")\n",
    "        continue\n",
    "\n",
    "    problem_name, prob_dict = mbore.problem_sets.get_problem_dict(\n",
    "        original_problem_name\n",
    "    )\n",
    "    total_problems = mbore.problem_sets.get_number_of_problems(prob_dict)\n",
    "    print(f\"Problem set: {problem_name:s}. {total_problems:d} total problems\")\n",
    "\n",
    "    # load in all the results and create a dictionary structured like:\n",
    "    #     D[problem_id][dim][fdim][scalarizer][(model, opt)] = {\n",
    "    #         'igd+': ..., 'hv': ..., 'Xtrs': ..., 'Ytrs': ...\n",
    "    #     }\n",
    "    D = {}\n",
    "    \n",
    "    total = total_problems * len(models_and_optimizers) * len(scalarizers)\n",
    "\n",
    "    with tqdm.notebook.tqdm(total=total, leave=False) as pbar:\n",
    "        for problem_id in prob_dict:\n",
    "            D[problem_id] = {}\n",
    "\n",
    "            for dim, fdims in prob_dict[problem_id]:\n",
    "                D[problem_id][dim] = {}\n",
    "\n",
    "                for fdim in fdims:\n",
    "                    D[problem_id][dim][fdim] = {}\n",
    "\n",
    "                    for scalarizer in scalarizers:\n",
    "                        D[problem_id][dim][fdim][scalarizer] = {}\n",
    "\n",
    "                        for model, model_opt_method in model_dict.items():\n",
    "                            if model == \"GP\":\n",
    "                                meth_gamma_start = None\n",
    "                                meth_gamma_end = None\n",
    "                                meth_gamma_schedule = None\n",
    "                            else:\n",
    "                                meth_gamma_start = gamma_start\n",
    "                                meth_gamma_end = gamma_end\n",
    "                                meth_gamma_schedule = gamma_schedule\n",
    "\n",
    "                            save_path = mbore.util.generate_save_filename(\n",
    "                                problem_name=problem_name,\n",
    "                                problem_id=problem_id,\n",
    "                                dim=dim,\n",
    "                                fdim=fdim,\n",
    "                                run_no=None,\n",
    "                                scalarizer=scalarizer,\n",
    "                                model=model,\n",
    "                                model_opt_method=model_opt_method,\n",
    "                                gamma_start=meth_gamma_start,\n",
    "                                gamma_end=meth_gamma_end,\n",
    "                                gamma_schedule=meth_gamma_schedule,\n",
    "                                save_dir=processed_results_dir,\n",
    "                            )\n",
    "\n",
    "                            with np.load(save_path) as fd:\n",
    "                                # ['Xtrs', 'Ytrs', 'hvs', 'igds', 'timing]\n",
    "                                # Xtrs = fd[\"Xtrs\"]\n",
    "                                # Ytrs = fd[\"Ytrs\"]\n",
    "                                hvs = fd[\"hvs\"]\n",
    "                                igds = fd[\"igds\"]\n",
    "                                timing = fd[\"timing\"]\n",
    "\n",
    "                            D[problem_id][dim][fdim][scalarizer][model] = {\n",
    "                                # \"Xtrs\": Xtrs,\n",
    "                                # \"Ytrs\": Ytrs,\n",
    "                                \"igd+\": igds,\n",
    "                                \"hv\": hvs,\n",
    "                                \"timing\": timing,\n",
    "                            }\n",
    "\n",
    "                            pbar.update()\n",
    "\n",
    "    \n",
    "    np.savez(savepath, D=D, original_problem_name=original_problem_name)\n",
    "    print(f\"Saved: {savepath:s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67232df",
   "metadata": {},
   "source": [
    "### Perform statistical comparisons for each set of problems\n",
    "Note that this all for each indicator\n",
    "\n",
    "- Per scalarisation:\n",
    "    - model is best per # of dimensions\n",
    "    - model is best per # of objectives\n",
    "- Which scalarisation and model combination is overall the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "141b5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base settings\n",
    "time = -1  # time index at which to compare methods [default: last idx (-1)]\n",
    "n_runs = 21\n",
    "\n",
    "# indicators and the direction of their stats tests, e.g., we want to \n",
    "# minimise IGD+ and maximise hypervolume (HV)\n",
    "indicators_and_args = [\n",
    "    (\"igd+\", np.argmin, \"less\"),\n",
    "    (\"hv\", np.argmax, \"greater\"),\n",
    "]\n",
    "\n",
    "n_methods = len(model_dict) # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcac7b",
   "metadata": {},
   "source": [
    "#### Which model is best per number of dimensions (for each scalarisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_problem_name in tqdm.notebook.tqdm(problem_names):\n",
    "\n",
    "    problem_name, prob_dict = mbore.problem_sets.get_problem_dict(\n",
    "        original_problem_name\n",
    "    )\n",
    "    total_problems = mbore.problem_sets.get_number_of_problems(prob_dict)\n",
    "\n",
    "    # load the results file\n",
    "    final_results_path = os.path.join(\n",
    "        final_results_dir, f\"{original_problem_name:s}.npz\"\n",
    "    )\n",
    "\n",
    "    # D[problem_id][dim][fdim][scalarizer][model][indicator]\n",
    "    # contains an np.ndarray of shape (n_runs, budget)\n",
    "    with np.load(final_results_path, allow_pickle=True) as fd:\n",
    "        assert fd[\"original_problem_name\"] == original_problem_name\n",
    "        D = fd[\"D\"].item()\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "    # model (i.e. GP, MLP, XGB) is best per problem, split by problem dims or objs\n",
    "    td = {}\n",
    "\n",
    "    with tqdm.notebook.tqdm(\n",
    "        total=total_problems * len(scalarizers) * len(indicators_and_args), \n",
    "        leave=False\n",
    "    ) as pbar:\n",
    "        for (indicator, argmethod, wilcoxon_side) in indicators_and_args:\n",
    "            td[indicator] = {}\n",
    "\n",
    "            for scalarizer in scalarizers:\n",
    "                td[indicator][scalarizer] = {}\n",
    "\n",
    "                # populate the data we wish to process\n",
    "                for problem_id in prob_dict:\n",
    "                    td[indicator][scalarizer][problem_id] = {}\n",
    "\n",
    "                    for dim, fdims in prob_dict[problem_id]:\n",
    "                        td[indicator][scalarizer][problem_id][dim] = {}\n",
    "\n",
    "                        for fdim in fdims:\n",
    "                            # storage\n",
    "                            best_seen_values = np.zeros((n_methods, n_runs))\n",
    "\n",
    "                            # extract the best seen values for each method\n",
    "                            for i, model in enumerate(model_dict):\n",
    "                                best_seen_values[i, :] = D[\n",
    "                                    problem_id\n",
    "                                ][dim][fdim][scalarizer][model][indicator][:, time]\n",
    "\n",
    "                            # do the stats testing -- one-sided wilcoxon\n",
    "                            # signed-rank test with holm-bonferroni correction\n",
    "                            (medians, mads, best_mask) = mbore.util.stats_test(\n",
    "                                best_seen_values, argmethod, wilcoxon_side\n",
    "                            )\n",
    "\n",
    "                            td[indicator][scalarizer][problem_id][dim][fdim] = {\n",
    "                                \"medians\": medians,\n",
    "                                \"mads\": mads,\n",
    "                                \"best_mask\": best_mask,\n",
    "                            }\n",
    "\n",
    "                            pbar.update()\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "    # which scalariser and model combo is best? i.e., which should we pick?\n",
    "    # this table just stores the median fitness values and the\n",
    "    # best values (or stats equal to best) values as a mask\n",
    "    # tds[indicator][scalerizer][problem_id][dim][fdim]\n",
    "    tds = {}\n",
    "\n",
    "    # gather up the keys for this list\n",
    "    n_scalarizers_and_models = len(scalarizers) * len(model_dict)\n",
    "\n",
    "    scalarizers_and_model_combos = [\n",
    "        (scalarizer, model)\n",
    "        for scalarizer in scalarizers\n",
    "        for model in model_dict\n",
    "    ]\n",
    "\n",
    "    with tqdm.notebook.tqdm(\n",
    "        total=len(indicators_and_args) * total_problems,\n",
    "        leave=False\n",
    ") as pbar:\n",
    "        for (indicator, argmethod, wilcoxon_side) in indicators_and_args:\n",
    "            tds[indicator] = {}\n",
    "\n",
    "            # populate the data we wish to process\n",
    "            for problem_id in prob_dict:\n",
    "                tds[indicator][problem_id] = {}\n",
    "\n",
    "                for dim, fdims in prob_dict[problem_id]:\n",
    "                    tds[indicator][problem_id][dim] = {}\n",
    "\n",
    "                    for fdim in fdims:\n",
    "\n",
    "                        best_seen_values = np.zeros(\n",
    "                            (n_scalarizers_and_models, n_runs)\n",
    "                        )\n",
    "\n",
    "                        for i, (scalarizer, model) in enumerate(\n",
    "                            scalarizers_and_model_combos\n",
    "                        ):\n",
    "                            # extract the best seen values for each method\n",
    "                            best_seen_values[i, :] = D[problem_id][dim][fdim][\n",
    "                                scalarizer\n",
    "                            ][model][indicator][:, time]\n",
    "\n",
    "                        # do the stats testing -- one-sided wilcoxon\n",
    "                        # signed-rank test with holm-bonferroni correction\n",
    "                        (medians, mads, best_mask) = mbore.util.stats_test(\n",
    "                            best_seen_values, argmethod, wilcoxon_side\n",
    "                        )\n",
    "\n",
    "                        tds[indicator][problem_id][dim][fdim] = {\n",
    "                            \"medians\": medians,\n",
    "                            \"mads\": mads,\n",
    "                            \"best_mask\": best_mask,\n",
    "                        }\n",
    "\n",
    "                        pbar.update()\n",
    "\n",
    "    savename = f\"{original_problem_name:s}_statstests.npz\"\n",
    "    savepath = os.path.join(final_results_dir, savename)\n",
    "    np.savez(\n",
    "        savepath, \n",
    "        td=td, \n",
    "        tds=tds, \n",
    "        original_problem_name=original_problem_name\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
